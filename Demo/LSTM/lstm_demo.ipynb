{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_demo2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM4ImmjE/K/9sP4HojxzTOs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-Quert/inlpfun/blob/master/Lab/Demo/LSTM/lstm_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgx0PKH0TzYJ",
        "colab_type": "text"
      },
      "source": [
        "#### Mount GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSxGu3_olnYR",
        "colab_type": "code",
        "outputId": "142ab2ba-a6db-49e5-b77b-7cab192a085a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGh9R0nJT3Ls",
        "colab_type": "text"
      },
      "source": [
        "#### Migrate TF1 code to TF2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YwQY54Tmlzf",
        "colab_type": "code",
        "outputId": "2a8c148d-8676-43ce-9607-cfff1cfb4370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf38g3sJAcTH",
        "colab_type": "text"
      },
      "source": [
        "#### Data dowloading (IMDb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfDeh_288kre",
        "colab_type": "code",
        "outputId": "527ae9dd-7011-4a09-bc0d-a7fdcecc144c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/adeshpande3/LSTM-Sentiment-Analysis.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LSTM-Sentiment-Analysis'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Total 74 (delta 0), reused 0 (delta 0), pack-reused 74\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzhW-gUJ8srV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xvzf /content/LSTM-Sentiment-Analysis/training_data.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN-Y4960a8rY",
        "colab_type": "code",
        "outputId": "57e67320-0cd4-4975-cbe1-ddff67fffea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!tar xvzf /content/LSTM-Sentiment-Analysis/models.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models/\n",
            "models/pretrained_lstm.ckpt-90000.meta\n",
            "models/pretrained_lstm.ckpt-90000.data-00000-of-00001\n",
            "models/pretrained_lstm.ckpt-90000.index\n",
            "models/checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbpcvUuc_d48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "!rm -rf /content/negativeReviews\n",
        "!rm -rf /content/positiveReviews\n",
        "!rm -rf /content/idsMatrix.npy\n",
        "!rm -rf /content/wordVectors.npy\n",
        "!rm -rf /content/wordsList.npy\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfZ6QVFzPe4h",
        "colab_type": "text"
      },
      "source": [
        "#### Steps\n",
        "- Training a word vector generation model (such as Word2Vec) or loading pretrained word vectors\n",
        "- Creating an ID's matrix for our training set\n",
        "- RNN (With LSTM units) graph creation\n",
        "- Training \n",
        "- Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtvfuUaFPp6u",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Training a word vector generation model (such as GloVe) or loading pretrained word vectors.\n",
        "- Pre-trained `GloVe` does more pre-process than `Word2Vec`.\n",
        "- `Word2Vec` model contains 3 million word vectors, each with a dimensionality of 300.\n",
        "- `GloVe` contains 400,000 word vectors, each with a dimensionality of 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JUXxwMrPoCi",
        "colab_type": "code",
        "outputId": "b599ef74-7bfa-4b7e-c5de-ba351505b34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "wordsList = np.load('/content/wordsList.npy')\n",
        "print('Loaded the word list')\n",
        "# Load as numpy array\n",
        "wordsList = wordsList.tolist()\n",
        "wordsList = [word.decode('UTF-8') for word in wordsList]\n",
        "wordVectors = np.load('/content/wordVectors.npy')\n",
        "print('Loaded the word vectors')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the word list\n",
            "Loaded the word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RUwXV3sS-eo",
        "colab_type": "code",
        "outputId": "c6632b11-551e-4240-e74e-c067e0103b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(wordsList))\n",
        "print(wordVectors.shape)\n",
        "# Embedding matrix: [400000, 50]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n",
            "(400000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoPg2OmKTHmW",
        "colab_type": "code",
        "outputId": "fb82beb9-5de8-45f3-a374-0fb4dc3fd8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Testing the index finding\n",
        "import tensorflow as tf\n",
        "max_seq_len = 10\n",
        "num_of_dim = 50\n",
        "id_matrix = np.zeros((max_seq_len), dtype = 'int32')\n",
        "sentence_test = 'i thought the movie was incredible and inspiring'\n",
        "sentence_test = sentence_test.split()\n",
        "len_of_sentence = len(sentence_test)\n",
        "for i in range(len_of_sentence):\n",
        "    id_matrix[i] = wordsList.index(sentence_test[i])\n",
        "\n",
        "print(id_matrix.shape)\n",
        "print(id_matrix)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n",
            "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXumKsoNF061",
        "colab_type": "code",
        "outputId": "91b5889e-f46d-40c5-998f-f603b67e8031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "firstSentence = np.zeros((max_seq_len), dtype='int32')\n",
        "firstSentence[0] = wordsList.index(\"i\")\n",
        "firstSentence[1] = wordsList.index(\"thought\")\n",
        "firstSentence[2] = wordsList.index(\"the\")\n",
        "firstSentence[3] = wordsList.index(\"movie\")\n",
        "firstSentence[4] = wordsList.index(\"was\")\n",
        "firstSentence[5] = wordsList.index(\"incredible\")\n",
        "firstSentence[6] = wordsList.index(\"and\")\n",
        "firstSentence[7] = wordsList.index(\"inspiring\")\n",
        "#firstSentence[8] and firstSentence[9] are going to be 0\n",
        "print(firstSentence.shape)\n",
        "print(firstSentence) #Shows the row index for each word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n",
            "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S1uy5TjEhLG",
        "colab_type": "code",
        "outputId": "3cc27069-d393-4a1c-db5d-7c9f87c78283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Input sequence -> Integerized Representation -> Embedding Matrix ->\n",
        "# tf.nn.embedding_lookup -> Sequence Vector\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    print(tf.nn.embedding_lookup(wordVectors, firstSentence).eval().shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jkfp-Vxor7s",
        "colab_type": "code",
        "outputId": "7283d76a-ee19-4cc4-a961-aa913af1d969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "positiveFiles = ['positiveReviews/' + f for f in listdir('/content/positiveReviews/') if isfile(join('positiveReviews/', f))]\n",
        "negativeFiles = ['negativeReviews/' + f for f in listdir('/content/negativeReviews/') if isfile(join('negativeReviews/', f))]\n",
        "numWords = []\n",
        "for pf in positiveFiles:\n",
        "    with open(pf, 'r', encoding = 'utf-8') as f:\n",
        "        line = f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)\n",
        "print('Positive files finished')\n",
        "\n",
        "for nf in negativeFiles:\n",
        "    with open(nf, 'r', encoding = 'utf-8') as f:\n",
        "        line = f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)\n",
        "print('Negative files finished')\n",
        "\n",
        "numFiles = len(numWords)\n",
        "print('The totall number of files is {0}'.format(numFiles))\n",
        "print('The total number of words in the files is {0}'.format(sum(numWords)))\n",
        "print('The average number of words in the files is {0}'.format(sum(numWords) / len(numWords)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive files finished\n",
            "Negative files finished\n",
            "The totall number of files is 25000\n",
            "The total number of words in the files is 5844680\n",
            "The average number of words in the files is 233.7872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z22gbz0VrDUK",
        "colab_type": "code",
        "outputId": "3acc8c59-440f-4783-e2ff-cba9b993a02f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.hist(numWords, 50)\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.axis([0, 1200, 0, 8000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1200.0, 0.0, 8000.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INAfb4HuqqR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_len = 250"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_EG8qF4ZJ_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removes punctuation, parentheses, question marks, etc., \n",
        "# and leaves only alphanumeric characters\n",
        "# Convert sequence to an ids matrix\n",
        "import re\n",
        "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
        "\n",
        "def cleanSentences(string):\n",
        "    string = string.lower().replace(\"<br />\", \" \")\n",
        "    return re.sub(strip_special_chars, \"\", string.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96z8bICgh-Oo",
        "colab_type": "text"
      },
      "source": [
        "#### Creating an id matrix for our training set\n",
        "#### [25000, 250]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pdEOAGJUcWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "fname = positiveFiles[3] #Can use any valid index (not just 3)\n",
        "with open(fname) as f:\n",
        "    for lines in f:\n",
        "        print(lines)\n",
        "        exit\n",
        "with open(fname) as f:\n",
        "    indexCounter = 0\n",
        "    line=f.readline()\n",
        "    cleanedLine = cleanSentences(line)\n",
        "    split = cleanedLine.split()\n",
        "    for word in split:\n",
        "        if indexCounter < max_seq_len:\n",
        "            try:\n",
        "                firstFile[indexCounter] = wordsList.index(word)\n",
        "            except ValueError:\n",
        "                firstFile[indexCounter] = 399999 #Vector for unknown words\n",
        "        indexCounter = indexCounter + 1\n",
        "firstFile\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP88th4_awMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = np.zeros((numFiles, max_seq_len), dtype='int32') # 25000, 250\n",
        "fileCounter = 0\n",
        "for pf in positiveFiles:\n",
        "   with open(pf, \"r\") as f:\n",
        "       indexCounter = 0\n",
        "       line=f.readline()\n",
        "       cleanedLine = cleanSentences(line)\n",
        "       split = cleanedLine.split()\n",
        "       for word in split:\n",
        "           try:\n",
        "               ids[fileCounter][indexCounter] = wordsList.index(word)\n",
        "           except ValueError:\n",
        "               ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
        "           indexCounter = indexCounter + 1\n",
        "           if indexCounter >= max_seq_len:\n",
        "               break\n",
        "       fileCounter = fileCounter + 1 \n",
        "\n",
        "for nf in negativeFiles:\n",
        "   with open(nf, \"r\") as f:\n",
        "       indexCounter = 0\n",
        "       line=f.readline()\n",
        "       cleanedLine = cleanSentences(line)\n",
        "       split = cleanedLine.split()\n",
        "       for word in split:\n",
        "           try:\n",
        "               ids[fileCounter][indexCounter] = wordsList.index(word)\n",
        "           except ValueError:\n",
        "               ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
        "           indexCounter = indexCounter + 1\n",
        "           if indexCounter >= maxSeqLength:\n",
        "               break\n",
        "       fileCounter = fileCounter + 1 \n",
        "# Pass into embedding function and see if it evaluates. \n",
        "\n",
        "np.save('idsMatrix', ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQE5w_YdzP8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = np.load('idsMatrix.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzOkBaPFcGgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper Functions\n",
        "from random import randint\n",
        "\n",
        "def getTrainBatch():\n",
        "    labels = []\n",
        "    arr = np.zeros([batchSize, max_seq_len])\n",
        "    for i in range(batchSize):\n",
        "        if (i % 2 == 0): \n",
        "            num = randint(1,11499)\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            num = randint(13499,24999)\n",
        "            labels.append([0,1])\n",
        "        arr[i] = ids[num-1:num]\n",
        "    return arr, labels\n",
        "\n",
        "def getTestBatch():\n",
        "    labels = []\n",
        "    arr = np.zeros([batchSize, max_seq_len])\n",
        "    for i in range(batchSize):\n",
        "        num = randint(11499,13499)\n",
        "        if (num <= 12499):\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            labels.append([0,1])\n",
        "        arr[i] = ids[num-1:num]\n",
        "    return arr, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5uQp3ttiHYK",
        "colab_type": "text"
      },
      "source": [
        "#### RNN (With LSTM units) graph creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZx4A_VfhtBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN Model\n",
        "batchSize = 24\n",
        "lstmUnits = 64\n",
        "numClasses = 2\n",
        "iterations = 50000\n",
        "num_of_dim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LPgPzI_h2NN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create placeholder for input_data and labels\n",
        "tf.compat.v1.reset_default_graph()\n",
        "input_data = tf.compat.v1.placeholder(tf.int32, [batchSize, max_seq_len])\n",
        "labels = tf.compat.v1.placeholder(tf.float32, [batchSize, numClasses])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAnu6Z4Qjqkq",
        "colab_type": "code",
        "outputId": "92db9770-57b8-4d11-f3b3-3652ac9bb34e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Once we have out input_data's placeholder, we are going to call tf.nn.lookup()\n",
        "# to get the word vectors.\n",
        "# Return 3-D tensor : batchSize * max_seq_len * num_of_dim [24, 250, 50]\n",
        "data = tf.Variable(tf.zeros([batchSize, max_seq_len, num_of_dim]), dtype = tf.float32)\n",
        "data = tf.nn.embedding_lookup(wordVectors, input_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_24l4bQJTxx",
        "colab_type": "code",
        "outputId": "4a1debfe-be31-4964-d89c-7afb1359b4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"embedding_lookup/Identity:0\", shape=(24, 250, 50), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vUAQmWPkudw",
        "colab_type": "code",
        "outputId": "f552fbfb-ea30-4b60-f8f3-aa540cd12256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Create LSTM model\n",
        "lstmCell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(lstmUnits)\n",
        "lstmCell = tf.compat.v1.nn.rnn_cell.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
        "# unrolling the whole network and creating a pathway for the data to flow through the RNN graph.\n",
        "value, _ = tf.compat.v1.nn.dynamic_rnn(cell=lstmCell, inputs=data, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-a4ee5b98d46e>:2: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-21-a4ee5b98d46e>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:740: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:744: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o1LsN9Il4q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Weight initialization\n",
        "weight = tf.Variable(tf.compat.v1.truncated_normal([lstmUnits, numClasses]))\n",
        "bias = tf.Variable(tf.constant(0.1, shape = [numClasses]))\n",
        "value = tf.transpose(value, [1, 0, 2])\n",
        "# Obtain the last value\n",
        "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
        "prediction = (tf.matmul(last, weight) + bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W96E7reAN8-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correctPred = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylIBN3-sOakj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLO2C1SWOstQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "tf.summary.scalar('Loss', loss)\n",
        "tf.summary.scalar('Accuracy', accuracy)\n",
        "merged = tf.compat.v1.summary.merge_all()\n",
        "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "writer = tf.compat.v1.summary.FileWriter(logdir, sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ls6NmkOPR6O",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9ZWUAixPJZa",
        "colab_type": "code",
        "outputId": "6b24f43c-92f7-4313-9d57-bda12dbdf64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!mkdir /content/drive/My\\ Drive/LAB/models\n",
        "sess = tf.compat.v1.InteractiveSession()\n",
        "saver = tf.compat.v1.train.Saver()\n",
        "sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "for i in range(iterations):\n",
        "   #Next Batch of reviews\n",
        "   nextBatch, nextBatchLabels = getTrainBatch();\n",
        "   sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
        "\n",
        "   #Write summary to Tensorboard\n",
        "   if (i % 100 == 0 and i != 0):\n",
        "       summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
        "       writer.add_summary(summary, i)\n",
        "\n",
        "   #Save the network every 10,000 training iterations\n",
        "   if (i % 10000 == 0 and i != 0):\n",
        "       save_path = saver.save(sess, \"/content/drive/My Drive/LAB/models/pretrained_lstm.ckpt\", global_step=i)\n",
        "       print(\"saved to %s\" % save_path)\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "saved to /content/drive/My Drive/LAB/models/pretrained_lstm.ckpt-10000\n",
            "saved to /content/drive/My Drive/LAB/models/pretrained_lstm.ckpt-20000\n",
            "saved to /content/drive/My Drive/LAB/models/pretrained_lstm.ckpt-30000\n",
            "saved to /content/drive/My Drive/LAB/models/pretrained_lstm.ckpt-40000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSGmoXW1VtKd",
        "colab_type": "code",
        "outputId": "6fbb8b25-648f-4e4c-eb0a-ed9c7d1b9457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sess = tf.compat.v1.InteractiveSession()\n",
        "saver = tf.compat.v1.train.Saver()\n",
        "saver.restore(sess, tf.compat.v1.train.latest_checkpoint('/content/drive/My Drive/LAB/models'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/LAB/models/pretrained_lstm.ckpt-40000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_aW637B9Krq",
        "colab_type": "text"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6UoyVFscUZO",
        "colab_type": "code",
        "outputId": "5383976c-34ba-42c0-b186-3b99b336372b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "iterations = 5000\n",
        "store_res = []\n",
        "for i in range(iterations):\n",
        "    nextBatch, nextBatchLabels = getTestBatch();\n",
        "    res = ((sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)\n",
        "    # print(\"Accuracy for this batch:\", res)\n",
        "    store_res.append(res)\n",
        "sum(store_res) / len(store_res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.21416682898998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}