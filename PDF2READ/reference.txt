# BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding (A1789) *****
https://github.com/google-research/bert

# AN EFFICIENT FRAMEWORK FOR LEARNING SENTENCE REPRESENTATIONS 
(A1788) ****
https://github.com/lajanugen/S2V

# Skip-Thought Vectors 
(A1787)
https://github.com/tensorflow/models/tree/master/research/skip_thoughts

# Named Entity Recognition with Bidirectional LSTM-CNNs 
(A1786)
https://github.com/zalandoresearch/flair
https://zhuanlan.zhihu.com/p/32085405

# OpenAI-GPT
(A1785) ****
https://zhuanlan.zhihu.com/p/52775384
https://www.cnblogs.com/huangyc/p/9860181.html#_label1
https://github.com/openai/finetune-transformer-lm

# Deep contextualized word representations (ELMo)
(A1784) ****
https://www.jiqizhixin.com/articles/2019-04-22-3
https://github.com/zalandoresearch/flair

# Attention Is All You Need (Transformer)
(A1783) ****
https://github.com/tensorflow/models/tree/master/official/transformer

# RESNET IN RESNET- GENERALIZING RESIDUAL ARCHITECTURES
(A1782)
https://github.com/osmr/imgclsmob

# Visualizing Attention in Transformer-Based Language Representation Models
# Representation Learning- A Review and New Perspectives

# Dropout- A Simple Way to Prevent Neural Networks from Overfitting
(A1781)

# Sequence to Sequence Learning with Neural Networks
(A1780)
https://github.com/farizrahman4u/seq2seq

# Layer Normalization
(A1779)

# Single Headed Attention RNN- Stop Thinking With Your Head
(A1778)

# How Does Batch Normalization Help Optimization?
(A1777)
https://github.com/jadevaibhav/Brain-Tumor-Segmentation-using-Deep-Neural-networks

# Batch Normalization- Accelerating Deep Network Training b y Reducing Internal Covariate Shift
(A1776)

# REFORMER- THE EFFICIENT TRANSFORMER
(A1775)
https://github.com/google/trax

# LARGE BATCH OPTIMIZATION FOR DEEP LEARNING:
TRAINING BERT IN 76 MINUTES (A1774)
https://github.com/microsoft/DeepSpeed

# Googleâ€™s Neural Machine Translation System- Bridging the Gap between Human and Machine Translation (A1773)
https://github.com/google/sentencepiece
https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition

# Pointer Sentinel Mixture Models (A1772)
https://github.com/elanmart/psmm

# Probing Neural Network Comprehension of Natural Language Arguments (A1771)
https://github.com/IKMLab/arct2

# Efficient Estimation of Word Representations in Vector Space(word2vec) (A1770)

# CS224U - Natural Language Understanding
https://www.youtube.com/watch?v=tZ_Jrc_nRJY&list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20
http://web.stanford.edu/class/cs224u/
https://github.com/cgpotts/cs224

# CS230 - Deep Learning
https://www.youtube.com/watch?v=PySo_6S4ZAg&list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb
https://cs230.stanford.edu/
https://github.com/cs230-stanford/cs230-code-examples

# CS20 - Tensorflow for Deep Learning Research
https://web.stanford.edu/class/cs20si/
https://github.com/aisolab/CS20
https://github.com/chiphuyen/stanford-tensorflow-tutorials

# CS224d - Deep Learning for Natural Language Processing
https://cs224d.stanford.edu
https://github.com/bogatyy/cs224d

# CS224N - NLP with Deep Learning
http://cs224n.stanford.edu/
https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z
https://github.com/hankcs/CS224n

# CS50 
https://cs50.harvard.edu/college/
https://github.com/cs50/python-cs50

# INSTRUCTORS
ANDREW NG
LEE-HUNG-YI
LEE-FEI-FEI

# Other
ELMo - https://www.jiqizhixin.com/articles/2019-04-22-3
Transformer - https://zhuanlan.zhihu.com/p/44121378
Zero-Shot Learning - https://zhuanlan.zhihu.com/p/34656727
Generalization - https://www.bilibili.com/read/cv3080245/
WordPiece - https://www.cnblogs.com/huangyc/p/10223075.html
ELMo, GPT & BERT - https://zhuanlan.zhihu.com/p/72309137
		 - https://www.youtube.com/watch?v=UYPa347-DdE			
AutoEncoder - https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-5-autoencoder/
NLP Process - https://www.zhihu.com/question/268849350
Softmax Regression - https://www.itread01.com/content/1545473582.html
		   - https://www.youtube.com/watch?v=LLux1SW--oM
	           - https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0
